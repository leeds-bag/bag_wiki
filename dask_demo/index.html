<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="Leeds BAG" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Speedy Python with Dask - Leeds BAG Wiki</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Speedy Python with Dask";
        var mkdocs_page_input_path = "dask_demo.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> Leeds BAG Wiki
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">How-to guides</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../linux_cheat_sheet/">Linux Cheat Sheet</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../python_quick_start/">Python Quick Start</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../VSCode_guide/">Using VSCode</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../conda_setup/">Mamba Set Up</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../how_to_regrid_xesmf_tutorial/">Regridding with Python</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">Speedy Python with Dask</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#without-using-dask">Without using dask</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#using-dask">Using dask</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#which-dimensions-to-chunk">Which dimensions to chunk?</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#the-effect-of-chunk-size">The effect of chunk size</a>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../printing/">Printing A1</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">Leeds BAG Wiki</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">How-to guides</li>
      <li class="breadcrumb-item active">Speedy Python with Dask</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/leeds-bag/bag_wiki/edit/main/docs/dask_demo.md">Edit on leeds-bag/bag_wiki</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h2 id="speeding-up-xarray-calculations-using-dask">Speeding up xarray calculations using dask</h2>
<p>This notebook demonstrates how to use the <code>dask</code> package to parallelise operations in xarray which (if used correctly and with some luck!) can massively speed up xarray.</p>
<p><strong>For this to work you first need to have installed <code>dask</code></strong> (and <code>xarray</code>, <code>netcdf4</code>, etc.)</p>
<p>This demonstration uses some ERA5 data which happens to be in <code>.grib</code> format but this should work with any data once it is opened using xarray</p>
<hr />
<p>First import packages, open the dataset, and define a decorator function that can be used to time functions. Note that you <strong>do not need to import dask</strong>. But we do import <code>dask.diagnostic</code>'s useful <code>ProgressBar</code></p>
<pre><code class="language-python">import xarray as xr
import pandas as pd
import numpy as np
from dask.diagnostics import ProgressBar
import time

ds = xr.open_dataset('/nfs/a68/eebjs/hardknott/drought/vpd_variables.grib',
                     engine='cfgrib')

# I got ChatGPT to write me this!
def timer(func):
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        print(f&quot;Function {func.__name__}&quot;,
              f&quot;took {round(end_time - start_time)}&quot;,
              &quot;seconds to execute.&quot;)
        return result
    return wrapper
</code></pre>
<p>On a multi-cored machine, dask will speed up xarray operations by performing calculations on multiple cores at the same time. For this to happen, the dataset/dataarray first has to be 'chunked.' For example, if you have a 1000x1000 sized <code>da</code> with dimensions <code>x</code>and <code>y</code>, you could split it into four 500x500 chunks:</p>
<pre><code>da = da.chunk({'x': 2, 'y': 2})
</code></pre>
<p>The <code>cpu_count</code> function from the multiprocessing module can check how may cores the machine you are using has:</p>
<pre><code class="language-python">from multiprocessing import cpu_count
print(cpu_count())
</code></pre>
<pre><code>32
</code></pre>
<p>The <code>ds</code> we have loaded in has three variables, surface pressure (<code>sp</code>), 2m temperature (<code>t2m</code>) and 2m dew point temperature (<code>d2m</code>). It is about 8Gb</p>
<pre><code class="language-python">print(ds)
</code></pre>
<pre><code>&lt;xarray.Dataset&gt;
Dimensions:     (time: 702, latitude: 1501, longitude: 3600)
Coordinates:
    number      int64 ...
  * time        (time) datetime64[ns] 1965-01-01 1965-02-01 ... 2023-06-01
    step        timedelta64[ns] ...
    surface     float64 ...
  * latitude    (latitude) float64 75.0 74.9 74.8 74.7 ... -74.8 -74.9 -75.0
  * longitude   (longitude) float64 -180.0 -179.9 -179.8 ... 179.7 179.8 179.9
    valid_time  (time) datetime64[ns] ...
Data variables:
    d2m         (time, latitude, longitude) float32 ...
    t2m         (time, latitude, longitude) float32 ...
    sp          (time, latitude, longitude) float32 ...
Attributes:
    GRIB_edition:            1
    GRIB_centre:             ecmf
    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts
    GRIB_subCentre:          0
    Conventions:             CF-1.7
    institution:             European Centre for Medium-Range Weather Forecasts
    history:                 2024-03-21T14:46 GRIB to CDM+CF via cfgrib-0.9.1...
</code></pre>
<p>These will be used to calculate vapour pressure deficit (vpd). This involves performing several operations using all three variables of the dataset. The calculation is performed using the following function.</p>
<pre><code class="language-python">def calculate_vpd(ds):

    t2m_c = ds['t2m'] - 273.15
    d2m_c = ds['d2m'] - 273.15
    sp_mb = ds['sp'] / 100

    # first calculate saturated vapour pressure
    fw = 1 + 7e-4 + 3.46e-6 * sp_mb
    svp = 6.112 * fw * np.exp( (17.67 * t2m_c) / (t2m_c + 243.5) )

    # then calculate actual vapour pressure
    avp = 6.112 * fw * np.exp( (17.67 * d2m_c) / (d2m_c + 243.5) )

    # then vapour pressure deficit is:
    vpd = svp - avp

    return vpd
</code></pre>
<hr />
<h3 id="without-using-dask">Without using dask</h3>
<p>First to get a baseline, we calculate without chunking (i.e. <strong>NOT</strong> using dask)</p>
<pre><code class="language-python">@timer
def calculate_vpd_without_chunking(ds):
    vpd = calculate_vpd(ds)
    return vpd

vpd = calculate_vpd_without_chunking(ds)
</code></pre>
<pre><code>Function calculate_vpd_without_chunking took 334 seconds to execute.
</code></pre>
<h3 id="using-dask">Using dask</h3>
<p>When you perform calculations with dask (e.g. <code>ds * 2</code>), the result will not yet be returned. Instead a 'delayed' result will be returned. The result can then either be calculated by calling the <code>.compute()</code> method, or it can be using to perform further operation where it will again return a delayed result. In this way, you can 'queue up` multiple operations and then perform them all at the same time.</p>
<p>When you call <code>.compute()</code>, an 'unchunked' dataset with the operation performed will be returned. If you want to keep the chunks but still return the result, you can instead call <code>.persist()</code></p>
<p>Now the same thing but using dask:</p>
<pre><code class="language-python">@timer
def calculate_vpd_with_chunking(ds):

    ds = ds.chunk({'time':24})

    vpd = calculate_vpd(ds)

    with ProgressBar():
        vpd = vpd.compute(num_workers=30, scheduler='threads')
    return vpd

vpd = calculate_vpd_with_chunking(ds)
</code></pre>
<pre><code>[########################################] | 100% Completed | 16.68 s
Function calculate_vpd_with_chunking took 22 seconds to execute.
</code></pre>
<p>In this case, the chunked version only took 22 seconds to run, over 15 times quicker than when not using dask.</p>
<hr />
<h3 id="which-dimensions-to-chunk">Which dimensions to chunk?</h3>
<p>In the above example, it shouldn't make too much of a difference which dimensions are chunked, because none of the calculations are being performed across dimensions. However, in the next example, we will take the rolling temporal mean, by calculating the annual means for each 36 months during 1965-2023. In this case, it is faster to calculate across dimensions that are not being reduced in the calculation (i.e. lat and lon). This is because it will be more efficient to calculate the mean if the time dimension is not chunked, so one core has all the values it needs to calculate the mean for a latlon gridcell, rather than time being split across cores.</p>
<p>First establish a baseline by performing the calculation without any chunking:</p>
<pre><code class="language-python">@timer
def calculate_spatial_mean_vpd_without_chunking(vpd):
    mean_vpd = vpd.rolling({'time':36}).mean(dim='time')
    return mean_vpd

mean_vpd = calculate_spatial_mean_vpd_without_chunking(ds)
</code></pre>
<pre><code>Function calculate_spatial_mean_vpd_without_chunking took 283 seconds to execute.
</code></pre>
<p>Now chunking across time (the <em>WRONG</em> way)</p>
<pre><code class="language-python">@timer
def calculate_mean_vpd_chunking_across_time(vpd):

    # chunk across time
    vpd = vpd.chunk({'time':24})

    # compute the mean
    with ProgressBar():
        mean_vpd = vpd.rolling({'time':36}).mean('time').compute(num_workers=30, scheduler='threads')
    return mean_vpd

mean_vpd = calculate_mean_vpd_chunking_across_time(vpd)
</code></pre>
<pre><code>[########################################] | 100% Completed | 79.81 s
Function calculate_mean_vpd_chunking_across_time took 105 seconds to execute.
</code></pre>
<pre><code class="language-python">@timer
def calculate_mean_vpd_chunking_across_space(vpd):

    # chunk across time
    vpd = vpd.chunk({'latitude':300, 'longitude':600})

    # compute the mean
    with ProgressBar():
        mean_vpd = vpd.rolling({'time':36}).mean('time').compute(num_workers=30, scheduler='threads')
    return mean_vpd

mean_vpd = calculate_mean_vpd_chunking_across_space(vpd)
</code></pre>
<pre><code>[########################################] | 100% Completed | 43.50 ss
Function calculate_mean_vpd_chunking_across_space took 67 seconds to execute.
</code></pre>
<p>In this example chunking the 'right' way was only about 1.5x faster than the wrong way, but this could be much more important depending on the shape of your array and types of operations being performed. In any case chunking was faster (3-4x) than doing the sample calculation without using dask.
Note that I tried to keep the total number of chunks similar in both examples to make this a fair comparison.</p>
<hr />
<h3 id="the-effect-of-chunk-size">The effect of chunk size</h3>
<p>Chunk size is another important thing to get right. It is usually worth playing around with a bit to make sure the size is efficient. Usually I try to chunk the array so the total number of chunks is about the same as the number of cores I am using (i.e. the <code>num_workers</code> argument)</p>
<p>The below code tests a range of chunk sizes in the time take to calculate the mean of vpd</p>
<pre><code class="language-python">da = vpd[:, :200, :200] # taking a smaller slice of the array so that the calculation is faster

def calculate_mean(da, chunksize):

    # time the chunking overhead
    start = time.time()
    da = da.chunk({'time':chunksize})
    end = time.time()
    chunking_time = end-start

    # time the actual calculation
    start = time.time()
    _ = da.mean(['latitude', 'longitude']).compute(num_workers=30, scheduler='threads')
    end = time.time()
    calculation_time = end-start

    return pd.Series(
        [chunking_time, calculation_time],
        index=['chunking time', 'calculation time']
                     )

results = pd.DataFrame()
for chunksize in [2,4,8,16,32,64,128, 256, 512]:
    results[chunksize] = calculate_mean(da, chunksize=chunksize)

results.T.plot.bar(grid=True, xlabel='chunksize', ylabel='time (seconds)',
                   stacked=True)
</code></pre>
<p><img alt="png" src="../assets/dask_demo_18_1.png" /></p>
<p>In this case the optimum chunksize seems to be around 64. The chunking time does not seem to vary much, but the calculation time does.
Let's try the same thing chunking across lat/lon</p>
<pre><code class="language-python">da = vpd[:10] # taking a smaller slice of the array so that the calculation is faster

def calculate_mean(da, chunksize):

    # time the chunking overhead
    start = time.time()
    da = da.chunk({'latitude':chunksize, 'longitude':chunksize})
    end = time.time()
    chunking_time = end-start

    # time the actual calculation
    start = time.time()
    _ = da.mean(['time']).compute(num_workers=30, scheduler='threads')
    end = time.time()
    calculation_time = end-start

    return pd.Series(
        [chunking_time, calculation_time],
        index=['chunking time', 'calculation time']
                     )

results = pd.DataFrame()
for chunksize in [20,40,80,160,320,640,1280, 2560]:
    results[chunksize] = calculate_mean(da, chunksize=chunksize)

results.T.plot.bar(grid=True, xlabel='chunksize', ylabel='time (seconds)',
                   stacked=True)
</code></pre>
<p><img alt="png" src="../assets/dask_demo_20_1.png" /></p>
<p>In this case it seems that larger chunks give a much better performance, with 640 being optimum. You can also chunk by setting the total number of chunks or letting dask choose the number of chunks with <code>chunks='auto'</code></p>
<pre><code class="language-python">da = vpd[:, :200, :200] # taking a smaller slice of the array so that the calculation is faster

def calculate_mean(da, chunksize):

    # time the chunking overhead
    start = time.time()
    da = da.chunk(chunksize)
    end = time.time()
    chunking_time = end-start

    # time the actual calculation
    start = time.time()
    _ = da.mean(['latitude', 'longitude']).compute(num_workers=30, scheduler='threads')
    end = time.time()
    calculation_time = end-start

    return pd.Series(
        [chunking_time, calculation_time],
        index=['chunking time', 'calculation time']
                     )


results = pd.DataFrame()
for chunksize in ['auto',600, 300,150,75,36,18]:
    print(chunksize)
    results[chunksize] = calculate_mean(da, chunksize=chunksize)

results.T.plot.bar(grid=True, xlabel='chunksize', ylabel='time (seconds)',
                   stacked=True)
</code></pre>
<p><img alt="png" src="../assets/dask_demo_22_2.png" /></p>
<p>But it looks like 'auto' isn't always the best! </p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../how_to_regrid_xesmf_tutorial/" class="btn btn-neutral float-left" title="Regridding with Python"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../printing/" class="btn btn-neutral float-right" title="Printing A1">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/leeds-bag/bag_wiki" class="fa fa-code-fork" style="color: #fcfcfc"> leeds-bag/bag_wiki</a>
        </span>
    
    
      <span><a href="../how_to_regrid_xesmf_tutorial/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../printing/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
